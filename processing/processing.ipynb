{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import music21 as m21\n",
    "from music21.key import Key\n",
    "from music21.interval import Interval\n",
    "from music21.pitch import Pitch\n",
    "from music21.converter import parseFile\n",
    "\n",
    "MSCORE_PATH = '/usr/bin/mscore'\n",
    "LILYPOND_PATH = '/usr/bin/lilypond'\n",
    "\n",
    "settings = m21.environment.UserSettings()\n",
    "\n",
    "settings['musicxmlPath'] = MSCORE_PATH\n",
    "settings['musescoreDirectPNGPath'] = MSCORE_PATH\n",
    "\n",
    "%load_ext music21.ipython21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "info\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import imp\n",
    "\n",
    "imp.reload(logging)\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.handlers.clear()\n",
    "\n",
    "#file handler\n",
    "log_filename = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_processing.log')\n",
    "fh = logging.FileHandler('../logs/' + log_filename)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "#console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.debug('debug')\n",
    "logger.info('info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_filename(row):\n",
    "    filename, url = parse_descriptor(row['files'])\n",
    "    return pd.Series({ 'filename': filename, 'url': url })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_descriptor(files_string):\n",
    "    try:\n",
    "        descriptors = json.loads(files_string.replace(\"'\", '\"'))\n",
    "    except ValueError as e:\n",
    "        logger.error('... files bad descriptor: %s', files_string)\n",
    "        raise\n",
    "        \n",
    "    if(len(descriptors) > 1):\n",
    "        logger.warn('Descriptor contains several files: %s', files_string)\n",
    "        \n",
    "    filename = os.path.basename(descriptors[0]['path'])\n",
    "    filename = filename.replace('.krn&f=midi', '.mid')\n",
    "    url = descriptors[0]['url']\n",
    "    \n",
    "    return filename, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_file_descriptors(dataframe):\n",
    "    descriptor_data = pd.DataFrame(dataframe.apply(extract_filename, axis=1))\n",
    "    return pd.concat([dataframe, descriptor_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataframe(metadata_path, files_path):\n",
    "    dataframe = pd.read_csv(metadata_path, dtype=str)\n",
    "    dataframe['input_dir'] = files_path\n",
    "    dataframe = dataframe[~dataframe['files'].isnull()]\n",
    "    dataframe = process_file_descriptors(dataframe)\n",
    "    dataframe = dataframe.fillna('')\n",
    "    return dataframe[dataframe['filename'].str.endswith('.mid', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kern_data = load_dataframe('../data/kernscores.csv', '../data/files_kernscores/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matched_instruments = [\n",
    "    'Piano', \n",
    "    'Harpsichord,Piano', \n",
    "    'Harpsichord,Piano,Clavichord',\n",
    "    'Piano Duet',\n",
    "    'Harpsichord,Clavichord,Piano',\n",
    "    'Piano,Harpsichord'\n",
    "]\n",
    "\n",
    "mutopia_data = load_dataframe('../data/mutopia.csv', '../data/files_mutopia/') \n",
    "mutopia_data = mutopia_data[mutopia_data['instruments'].isin(matched_instruments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pianomidi_data = load_dataframe('../data/pianomidi.csv', '../data/files_pianomidi/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yamaha_data = pd.read_csv('../data/yamaha/metadata.csv', dtype='str')\n",
    "yamaha_data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call_safe(func, args, default=None):\n",
    "    try:\n",
    "        return func(*args)\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(score, key_str):\n",
    "    key = m21.key.Key(key_str.split()[0])\n",
    "    \n",
    "    if key.mode == 'major':\n",
    "        i = Interval(key.tonic, Pitch('C'))\n",
    "\n",
    "    elif key.mode == 'minor':\n",
    "        i = Interval(key.tonic, Pitch('A'))\n",
    "        \n",
    "    score.transpose(i, inPlace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_metadata(score, score_metadata):\n",
    "    if score.metadata is None:\n",
    "        score.metadata = m21.stream.metadata.Metadata()\n",
    "        \n",
    "    score.metadata.composer = score_metadata['composer']\n",
    "    score.metadata.title = score_metadata['name']\n",
    "    score.metadata.movementName = score_metadata['name']\n",
    "    \n",
    "    try:\n",
    "        score.metadata.date = score_metadata['year']\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_time_signatures(score):\n",
    "    for part in score.parts:\n",
    "        time_signatures = [m.timeSignature for m in part.getElementsByClass(m21.stream.Measure) if m.timeSignature is not None]\n",
    "        if time_signatures:\n",
    "            return [ts.ratioString for ts in time_signatures]\n",
    "    \n",
    "    return [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hard way to extract duration:\n",
    "# metronome_data = pd.DataFrame(score.metronomeMarkBoundaries(), columns=['start', 'end', 'tempo'])\n",
    "# metronome_data['duration'] = metronome_data['end'] - metronome_data['start']\n",
    "# metronome_data['bpm'] = metronome_data['tempo'].map(lambda x: x.number)\n",
    "# metronome_data['weighted_duration'] = metronome_data['bpm'] * metronome_data['duration']\n",
    "# tempo = metronome_data['weighted_duration'].sum() /  metronome_data['duration'].sum()\n",
    "# tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_stats(score):\n",
    "    key_signature = score.analyze('key')\n",
    "    primary_ts, *alternative_ts = call_safe(extract_time_signatures, [score], default=[None])\n",
    "    duration = call_safe(lambda s: max([x['endTimeSeconds'] for x in s.secondsMap]), [score])      \n",
    "    tempo = call_safe(lambda s: s.metronomeMarkBoundaries()[0][2].number, [score]) \n",
    "        \n",
    "    \n",
    "    return {\n",
    "        'key': str(key_signature),\n",
    "        'primary_time_signature': primary_ts,\n",
    "        'secondary_time_signatures': alternative_ts,\n",
    "        'duration': duration,\n",
    "        'tempo': tempo\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_extension(filename, new_ext):\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    return base + '.' + new_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_file(input_path):\n",
    "    _, ext = os.path.splitext(input_path)\n",
    "    if ext != '.xml' and ext != '.mxl':\n",
    "        tmp_path = input_path + '.tmp.xml'\n",
    "        subprocess.call('mscore \"{0}\" -o \"{1}\"'.format(input_path, tmp_path), shell=True)\n",
    "        return m21.converter.parseFile(tmp_path)\n",
    "    else:\n",
    "        return m21.converter.parseFile(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "    \n",
    "def process_row(row, output_dir, global_time_started):\n",
    "    hasError = False\n",
    "    output_path = None\n",
    "    key_signature = None\n",
    "    primary_ts = None\n",
    "    alternative_ts = None\n",
    "    url = None\n",
    "    score_stats = {\n",
    "        'key': None,\n",
    "        'primary_time_signature': None,\n",
    "        'secondary_time_signatures': None,\n",
    "        'duration': None,\n",
    "        'tempo': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        logger.debug('Processing %s...', row['name'])\n",
    "        time_started = time.time()\n",
    "        \n",
    "        input_path = os.path.join(row['input_dir'], row['filename'])\n",
    "        output_path = os.path.join(output_dir, set_extension(row['filename'], 'xml'))\n",
    "        \n",
    "        score = parse_file(input_path)\n",
    "        logger.debug('\\t...file parsed')\n",
    "        \n",
    "        score_stats = extract_stats(score)\n",
    "        logger.debug('\\t...stats extractes: %s', json.dumps(score_stats))\n",
    "    \n",
    "        normalize(score, score_stats['key'])\n",
    "        update_metadata(score, row)\n",
    "        logger.debug('\\t...score normalized and updated')\n",
    "        \n",
    "        score.write('musicxml', output_path)\n",
    "        logger.debug('\\t...file processed. Processing time: %s', time.time() - time_started)\n",
    "        logger.info('Processed file %i. Time elapsed %s', row.name, time.time() - global_time_started)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error('Exception occured')\n",
    "        logger.debug('Exception details: ', exc_info=e)\n",
    "        hasError = True\n",
    "        \n",
    "    return pd.Series({\n",
    "            'genre': row['genre'],\n",
    "            'input_dir': row['input_dir'],\n",
    "            'details_url': row['details_url'],\n",
    "            'filename_mid' : rowp['filename'],\n",
    "            'name': row['name'],\n",
    "            'year': row['year'],\n",
    "            'composer': row['composer'],\n",
    "            'filename_xml': output_path,\n",
    "            'source_url': url,\n",
    "            'key': score_stats['key'],\n",
    "            'primary_time_signature': score_stats['primary_time_signature'],\n",
    "            'secondary_time_signatures': score_stats['secondary_time_signatures'],\n",
    "            'duration': score_stats['duration'],\n",
    "            'tempo': score_stats['tempo'],\n",
    "            'hasError': hasError\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_dataframe(dataframe, output_dir):\n",
    "    time_started = time.time()\n",
    "    total_rows = len(dataframe.index)\n",
    "    logger.info('Processing files in dataframe. Total items: %i', total_rows)\n",
    "    result = dataframe.apply(lambda row: process_row(row, '../data/output/', time_started), axis=1)\n",
    "    logger.info('Finished processing dataframe')\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([mutopia_data, kern_data, pianomidi_data, yamaha_data])\n",
    "dataset.reset_index(inplace=True)\n",
    "del dataset['index']\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame()\n",
    "CHUNK_SIZE = 100\n",
    "\n",
    "for i in range(0, len(dataset.index), CHUNK_SIZE):\n",
    "    chunk = dataset[i:i+CHUNK_SIZE]\n",
    "    logger.info('processing chunk {0} to {1}'.format(i, i+CHUNK_SIZE))\n",
    "    metadata = pd.concat([metadata, process_dataframe(chunk, '../data/output/xml')])\n",
    "    metadata.to_csv('metatada.backup.{0}.csv'.format(i))\n",
    "    logger.info('...done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename_abc(input_filename):\n",
    "    output_file, _ = os.path.splitext(os.path.basename(input_filename))\n",
    "    return '../data/output/abc/' +  output_file + '.abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_semitones_to_cdur(key_string):\n",
    "    try:\n",
    "        key = m21.key.Key(key_string.split()[0])\n",
    "        if key.mode == 'major':\n",
    "            interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch('C'))\n",
    "            return interval.semitones\n",
    "        if key.mode == 'minor':\n",
    "            interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch('A'))\n",
    "            return interval.semitones\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    logger.error('Bad key string: %s', key_string)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    filename = row['filename_abc']\n",
    "    basename = os.path.basename(filename)\n",
    "    semitones = get_semitones_to_cdur(row['key'])\n",
    "    \n",
    "    if semitones is not None:\n",
    "        command = 'abc2abc \"{0}\" -d -t {1} > \"../data/output/abc_transposed/{2}\"'.format(filename, semitones, basename)\n",
    "        subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checks\n",
    "metadata = metadata[~metadata['hasError']]\n",
    "\n",
    "if not all(metadata['filename_abc'].map(lambda fname: os.path.isfile(fname))):\n",
    "    logger.error('missing abc files!')\n",
    "    \n",
    "if not all(metadata['filename_xml'].map(lambda fname: os.path.isfile(fname))):\n",
    "    logger.error('missing xml files!')\n",
    "    \n",
    "if not all(metadata['filename_mid'].map(lambda fname: os.path.isfile(fname))):\n",
    "    logger.error('missing mid files!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('../data/output/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata['time_signature'] = None\n",
    "metadata['secondary_time_signatures'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_time_signature(row):\n",
    "    if row['time_signature'] is not None:\n",
    "        return pd.Series({\n",
    "            'time_signature': row['time_signature'],\n",
    "            'secondary_time_signatures': row['secondary_time_signatures']\n",
    "        })\n",
    "    \n",
    "    filename = row['filename_xml']\n",
    "    score = m21.converter.parseFile(filename)\n",
    "    primary_ts, *alternative_ts = call_safe(extract_time_signatures, [score], default=[None])\n",
    "    logger.debug('%s: extracted primary time signature: %s', filename, primary_ts)\n",
    "    return pd.Series({\n",
    "            'time_signature': primary_ts,\n",
    "            'secondary_time_signatures': '; '.join(alternative_ts)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = metadata.apply(parse_time_signature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2/4\n",
       "1    3/4\n",
       "2    2/2\n",
       "3    6/8\n",
       "4    6/8\n",
       "Name: primary_time_signature, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "del metadata['primary_time_signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del metadata['secondary_time_signatures']\n",
    "del metadata['time_signature']\n",
    "metadata = pd.concat([metadata, result], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>hasError</th>\n",
       "      <th>source_url</th>\n",
       "      <th>tempo</th>\n",
       "      <th>year</th>\n",
       "      <th>year_exact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2187.000000</td>\n",
       "      <td>2187</td>\n",
       "      <td>0</td>\n",
       "      <td>2187.000000</td>\n",
       "      <td>822.000000</td>\n",
       "      <td>2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>223.170912</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.157293</td>\n",
       "      <td>1819.451338</td>\n",
       "      <td>0.275263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>221.959010</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.066431</td>\n",
       "      <td>60.970446</td>\n",
       "      <td>0.446749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.727273</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1720.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1775.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>160.761450</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>1828.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>272.497926</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2156.893319</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          duration hasError  source_url        tempo         year year_exact\n",
       "count  2187.000000     2187           0  2187.000000   822.000000       2187\n",
       "mean    223.170912        0         NaN   115.157293  1819.451338   0.275263\n",
       "std     221.959010        0         NaN    42.066431    60.970446   0.446749\n",
       "min       8.727273    False         NaN    18.000000  1720.000000      False\n",
       "25%      90.000000        0         NaN    84.000000  1775.000000          0\n",
       "50%     160.761450        0         NaN   112.000000  1828.000000          0\n",
       "75%     272.497926        0         NaN   141.000000  1850.000000          1\n",
       "max    2156.893319    False         NaN   300.000000  2008.000000       True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata.to_csv('../output/metadata.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
